{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7110f2a7-a6f7-4545-91d3-e2ef29479990",
   "metadata": {},
   "source": [
    "## Import Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c8bb823-9965-4a93-803a-27e78595f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.teleprompt import COPRO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfba7a00-5d90-49f2-b6ed-eba315951eed",
   "metadata": {},
   "source": [
    "### Downloading & Exploring Dataset\n",
    "The dataset can be seen/understood from here: [Dataset Page](https://huggingface.co/datasets/Divyanshu/indicxnli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e791befe-6c97-4fe5-b456-2761dd73856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Hindi(hi) Dataset. If it's first time, dataset will get downloaded at the location specified against \"cache_dir\" variable\n",
    "dataset = load_dataset(\"Divyanshu/indicxnli\", \"hi\", cache_dir=os.path.join(os.getcwd(), \"datasets\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686c2386-021d-448a-b770-8671629f91a1",
   "metadata": {},
   "source": [
    "<b>Viewing one datapoint</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84501ec4-6673-488a-b240-5e28a0a50612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'उह, मैं अभी भी एक था और केवल नौ दो-दो कि कभी नियामक पर इंजेक्शन सेट किया था।',\n",
       " 'hypothesis': 'मैं 922 था.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = random.choice(['train', 'test', 'validation'])\n",
    "index = random.randint(0, 2490)\n",
    "\n",
    "dataset[split][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0bb1f5-9df5-436a-aa86-d7940f9fcb30",
   "metadata": {},
   "source": [
    "<b>Premise</b>:  This is the initial statement or piece of text that provides factual information or context. It serves as the foundation or given information that we assume to be true for the inference task.\n",
    "\n",
    "<b>Hypothesis</b>: This is a statement that may or may not follow logically from the premise. It's the claim we want to test against the premise to determine the logical relationship.\n",
    "\n",
    "<b>Label</b>: This indicates the relationship between the premise and hypothesis:\n",
    "\n",
    "Integer label `0` if hypothesis `entails` the premise, `2` if hypothesis `negates` the premise and `1` otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5861a84-c999-443d-afc0-1847417c103c",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eab952-a0c4-438d-936c-7442d189eb83",
   "metadata": {},
   "source": [
    "#### Configuring LLM for DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31ded226-ad5e-4b42-8b2f-be0ec7450014",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = dspy.LM('openai/gpt-4o-mini', api_key = os.getenv('OPENAI_API_KEY'))\n",
    "dspy.configure(lm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25acdd5e-44be-42b1-b9de-7e29f20bc788",
   "metadata": {},
   "source": [
    "---\n",
    "Creating the `dataloader` function to load and return the datapoints as `dspy.Example` object.\n",
    "\n",
    "#### dspy.Example\n",
    "The core data type for data in DSPy is `Example`. `Example` represents items in training and test datasets. While doing evaluation & optimization runs, an individual datapoint will be of type `Example`.\n",
    "\n",
    "`Example` objects have `with_inputs()` method that marks specific fields as inputs. The rest are labels or metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4703bccb-cb8b-4709-b7bf-ba08a85d2a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_indicxlni(dataset, split=\"validation\", nos_of_points=-1):\n",
    "    if nos_of_points == -1:\n",
    "        data_df = pd.DataFrame(dataset[split])\n",
    "    else:\n",
    "        data_df = pd.DataFrame(dataset[split]).head(nos_of_points)\n",
    "    \n",
    "    label_map = {\n",
    "        0: \"Yes\",\n",
    "        1: \"Neutral\",\n",
    "        2: \"No\"\n",
    "    }\n",
    "    \n",
    "    def as_dspy_example(row):\n",
    "        return dspy.Example({\n",
    "            \"premise\": row['premise'],\n",
    "            \"hypothesis\": row['hypothesis'],\n",
    "            \"answer\": label_map[row['label']]\n",
    "        }).with_inputs(\"premise\", \"hypothesis\")\n",
    "\n",
    "    return list(data_df.apply(as_dspy_example, axis=1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7293f0-a91a-4b39-993e-3fdf4433ad99",
   "metadata": {},
   "source": [
    "##### Train | Dev | Test Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8f5545-63a3-4fd7-a194-81764bbae510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set:  50\n",
      "Size of dev set:  10\n"
     ]
    }
   ],
   "source": [
    "all_train_set = load_indicxlni(dataset, \"train\")\n",
    "all_dev_set = load_indicxlni(dataset, \"validation\")\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(all_train_set)\n",
    "random.shuffle(all_dev_set)\n",
    "\n",
    "# 50 random train sample and 10 random dev sample\n",
    "train_set, dev_set = all_train_set[: 50], all_dev_set[:10]\n",
    "\n",
    "print(\"Size of training set: \", len(train_set))\n",
    "print(\"Size of dev set: \", len(dev_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57616a87-9386-4b70-af5e-eecc2d0cbe6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test set:  10\n"
     ]
    }
   ],
   "source": [
    "all_test_set = load_indicxlni(dataset, \"test\")\n",
    "\n",
    "random.shuffle(all_test_set)\n",
    "\n",
    "test_set = all_test_set[:10]\n",
    "print(\"Size of test set: \", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8491df75-7963-4514-abaa-14846e20bcec",
   "metadata": {},
   "source": [
    "### dspy.Signature\n",
    "\n",
    "`Signature` define the input-output behaviour of LLM calls in a declarative way. Let's define a signature for our dataset where `premise` and `hypothesis` would be inputs to the LLM or prompt and `answer` would be returned by the LLM.\n",
    "\n",
    "The `doc_string` serves as the prompt to be sent to the LLM with the variables defined in the class as inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c606bdf-4854-4b5a-8d02-6e33bc37a217",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndicXLNISignature(dspy.Signature):\n",
    "    (\"\"\"You are given a premise and a hypothesis.\"\"\"\n",
    "    \"\"\"You must indicate with Yes/No/Neutral answer whether we can logically conclude the hypothesis from the premise.\"\"\")\n",
    "\n",
    "    premise = dspy.InputField()\n",
    "    hypothesis = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"Yes or No or Neutral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a94fcf-b23f-4e24-8269-ec7e0908b676",
   "metadata": {},
   "source": [
    "Let's use a basic `dspy.Module` to see the prompt created with the above `Signature` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6488f148-1783-49c5-9fc7-f21ca67c4c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    answer='Yes'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "basic_prediction = dspy.Predict(IndicXLNISignature)\n",
    "\n",
    "prediction = basic_prediction(premise = dataset['train'][5]['premise'], hypothesis = dataset['train'][5]['hypothesis'])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29cfe32-684e-43a8-8d80-749c586317be",
   "metadata": {},
   "source": [
    "The prompt sent or used for the above prediction can be obtained and is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd3ec074-d5ce-45d6-afee-bbebd4fdffb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': None,\n",
       "  'messages': [{'role': 'system',\n",
       "    'content': 'Your input fields are:\\n1. `premise` (str): \\n2. `hypothesis` (str):\\nYour output fields are:\\n1. `answer` (str): Yes or No or Neutral\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\n\\n[[ ## premise ## ]]\\n{premise}\\n\\n[[ ## hypothesis ## ]]\\n{hypothesis}\\n\\n[[ ## answer ## ]]\\n{answer}\\n\\n[[ ## completed ## ]]\\nIn adhering to this structure, your objective is: \\n        You are given a premise and a hypothesis.You must indicate with Yes/No/Neutral answer whether we can logically conclude the hypothesis from the premise.'},\n",
       "   {'role': 'user',\n",
       "    'content': '[[ ## premise ## ]]\\nमेरा वॉकमैन टूट गया तो मैं अब परेशान हूँ.... मुझे बस स्टीरियो को असली जोर से चलाना है\\n\\n[[ ## hypothesis ## ]]\\nमैं परेशान हूं कि मेरा वॉकमैन टूट गया और अब मुझे स्टीरियो को जोर से चलाना पड़ रहा है।\\n\\nRespond with the corresponding output fields, starting with the field `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.'}],\n",
       "  'kwargs': {},\n",
       "  'response': ModelResponse(id='chatcmpl-BkmeTZDSy2hKXQ8WaFLiYVK42jcdQ', created=1750489805, model='gpt-4o-mini-2024-07-18', object='chat.completion', system_fingerprint='fp_34a54ae93c', choices=[Choices(finish_reason='stop', index=0, message=Message(content='[[ ## answer ## ]]\\nYes\\n\\n[[ ## completed ## ]]', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]))], usage={}, service_tier='default', cache_hit=None),\n",
       "  'outputs': ['[[ ## answer ## ]]\\nYes\\n\\n[[ ## completed ## ]]'],\n",
       "  'usage': {},\n",
       "  'cost': 4.3349999999999997e-05,\n",
       "  'timestamp': '2025-06-21T13:53:21.739607',\n",
       "  'uuid': '763877ef-eef7-4d48-9855-c6d174a8f6b1',\n",
       "  'model': 'openai/gpt-4o-mini',\n",
       "  'response_model': 'gpt-4o-mini-2024-07-18',\n",
       "  'model_type': 'chat'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_prediction.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b744f2-5bd6-4f26-a99b-90d35cd8b213",
   "metadata": {},
   "source": [
    "---\n",
    "#### dspy.Module\n",
    "\n",
    "DSPy Module abstracts prompting technique. We've already seen `dspy.Predict()` module before which is for basic prompting.\n",
    "\n",
    "We will use advanced prompting technique, Chain Of Thought (COT), for this project, and we will use `dspy.ChainOfThought()` module for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a7c6105-5b7c-465e-bad4-f10bfb6bc895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndicXLNICOT(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.ChainOfThought(IndicXLNISignature)\n",
    "\n",
    "    def forward(self, premise, hypothesis):\n",
    "        return self.generate_answer(premise=premise, hypothesis=hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce169d67-02ec-4675-a61c-f6d339116bdf",
   "metadata": {},
   "source": [
    "Let's see how different this prompt would be as compared to `dspy.Predict()` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73fa50a2-5520-4317-ad06-2845f40740f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='प्रस्तावना में केवल यह कहा गया है कि स्लेट ने जैक्सन के निष्कर्षों को पढ़ा है, लेकिन यह नहीं बताया गया है कि स्लेट की जैक्सन के निष्कर्षों पर कोई राय थी या नहीं। इसलिए, हम यह नहीं कह सकते कि स्लेट की जैक्सन के निष्कर्षों पर कोई राय थी।',\n",
      "    answer='No'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cot_zeroshot = IndicXLNICOT()\n",
    "\n",
    "cot_prediction = cot_zeroshot(premise = dataset['train'][7]['premise'], hypothesis = dataset['train'][7]['hypothesis'])\n",
    "print(cot_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2472ede0-8fc0-44f6-9080-b24cd75cafcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': None,\n",
       " 'messages': [{'role': 'system',\n",
       "   'content': 'Your input fields are:\\n1. `premise` (str): \\n2. `hypothesis` (str):\\nYour output fields are:\\n1. `reasoning` (str): \\n2. `answer` (str): Yes or No or Neutral\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\n\\n[[ ## premise ## ]]\\n{premise}\\n\\n[[ ## hypothesis ## ]]\\n{hypothesis}\\n\\n[[ ## reasoning ## ]]\\n{reasoning}\\n\\n[[ ## answer ## ]]\\n{answer}\\n\\n[[ ## completed ## ]]\\nIn adhering to this structure, your objective is: \\n        You are given a premise and a hypothesis.You must indicate with Yes/No/Neutral answer whether we can logically conclude the hypothesis from the premise.'},\n",
       "  {'role': 'user',\n",
       "   'content': '[[ ## premise ## ]]\\n(स्लेट के जैक्सन के निष्कर्षों को पढ़ने के लिए पढ़ें।)\\n\\n[[ ## hypothesis ## ]]\\nजैक्सन के निष्कर्षों पर स्लेट की राय थी।\\n\\nRespond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.'}],\n",
       " 'kwargs': {},\n",
       " 'response': ModelResponse(id='chatcmpl-BkmurNnbPgV1woSdeJa34voGJeDmk', created=1750490821, model='gpt-4o-mini-2024-07-18', object='chat.completion', system_fingerprint='fp_34a54ae93c', choices=[Choices(finish_reason='stop', index=0, message=Message(content='[[ ## reasoning ## ]]\\nप्रस्तावना में केवल यह कहा गया है कि स्लेट ने जैक्सन के निष्कर्षों को पढ़ा है, लेकिन यह नहीं बताया गया है कि स्लेट की जैक्सन के निष्कर्षों पर कोई राय थी या नहीं। इसलिए, हम यह नहीं कह सकते कि स्लेट की जैक्सन के निष्कर्षों पर कोई राय थी। \\n\\n[[ ## answer ## ]]\\nNo\\n\\n[[ ## completed ## ]]', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]))], usage={}, service_tier='default'),\n",
       " 'outputs': ['[[ ## reasoning ## ]]\\nप्रस्तावना में केवल यह कहा गया है कि स्लेट ने जैक्सन के निष्कर्षों को पढ़ा है, लेकिन यह नहीं बताया गया है कि स्लेट की जैक्सन के निष्कर्षों पर कोई राय थी या नहीं। इसलिए, हम यह नहीं कह सकते कि स्लेट की जैक्सन के निष्कर्षों पर कोई राय थी। \\n\\n[[ ## answer ## ]]\\nNo\\n\\n[[ ## completed ## ]]'],\n",
       " 'usage': {},\n",
       " 'cost': 9.389999999999999e-05,\n",
       " 'timestamp': '2025-06-21T13:55:02.581388',\n",
       " 'uuid': '0db06a7d-30c4-4244-b25c-5aa992b4d28f',\n",
       " 'model': 'openai/gpt-4o-mini',\n",
       " 'response_model': 'gpt-4o-mini-2024-07-18',\n",
       " 'model_type': 'chat'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_zeroshot.history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b59108c-7fce-4a4a-9277-3afccf9a4e5e",
   "metadata": {},
   "source": [
    "---\n",
    "#### Metrics & Evaluator\n",
    "\n",
    "In DSPy, metric is a function that will take examples from your data and the output of LLM and return a score that quantifies how good the output is.\n",
    "\n",
    "For simple classification or short-form QA tasks, this could be just \"accuracy\", or \"exact match\" or \"F1-Score\". For long-form outputs, metric could be a smaller DSPy program that checks multiple properties of the output(using AI feedback from LLMs).\n",
    "\n",
    "Simpler metrics are already defined in DSPY:\n",
    "- `dspy.evaluate.metrics.answer_exact_match`\n",
    "- `dspy.evaluate.metrics.answer_passage_match`\n",
    "\n",
    "The metrics could be more complex, e.g. check for multiple properties. For that, write your own function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4fddad3-a61b-4cce-b5b7-0a67a957634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicxlni_accuracy = dspy.evaluate.metrics.answer_exact_match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd69fc4f-f2a1-4989-82a1-d1d722368c9d",
   "metadata": {},
   "source": [
    "Once metric is decided/defined, evaluations can be done either in a simple Python loop:\n",
    "\n",
    "```\n",
    "scores = []\n",
    "for x in devset:\n",
    "    pred = program(**x.inputs())\n",
    "    score = metric(x, pred)\n",
    "    scores.append(score)\n",
    "```\n",
    "\n",
    "or can use built-in utilites in `Evaluate` utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee9d1ab0-06a3-4981-8979-6cb181ea4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluate(devset=test_set, num_threads=1, display_progress=True, display_table=len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e10c04d-10ed-4672-b675-7c594c6dd46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 10 (70.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 99.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 13:56:28 INFO dspy.evaluate.evaluate: Average Metric: 7 / 10 (70.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>example_answer</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>सुरक्षा सुनिश्चित करने के लिए जनरेटरों को बंद करना पड़ा और लिफ्ट ब...</td>\n",
       "      <td>जनरेटर एक सुरक्षा जोखिम थे।</td>\n",
       "      <td>Yes</td>\n",
       "      <td>प्रस्तावना में कहा गया है कि सुरक्षा सुनिश्चित करने के लिए जनरेटरो...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>भगवान का उल्लेख केवल प्रकृति के भगवान के रूप में किया जाता है, जिस...</td>\n",
       "      <td>लोग अलग-अलग होंगे लेकिन समान होंगे।</td>\n",
       "      <td>Yes</td>\n",
       "      <td>प्रस्तावना में कहा गया है कि सभी लोगों को राष्ट्रों के समुदाय में ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>अप्रैल १८६५ में उस व्यक्ति की हत्या के साथ, जिसने विचारों के एक नए...</td>\n",
       "      <td>इस हमले को रूस ने अंजाम दिया था।</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>प्रस्तावना में यह कहा गया है कि एक व्यक्ति की हत्या अप्रैल 1865 मे...</td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>दूसरे शब्दों में, क्या होता है कुछ की तरह है एक जादूगर के अब-तुम-अ...</td>\n",
       "      <td>जो हो रहा है वह हैरान करने वाला है।</td>\n",
       "      <td>Yes</td>\n",
       "      <td>प्रस्तावना में एक जादूगर के कार्यों का उल्लेख किया गया है, जो आमतौ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>आप जानते हैं, आप नहीं बच सकते, आप जीवित नहीं रह सकते अगर आपके पास ...</td>\n",
       "      <td>आपको 5000 फीट से अधिक काउंटर प्रेशर की जरूरत होती है।</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>प्रस्तावना में कहा गया है कि ऊंचाइयों पर सांस लेने के लिए काउंटर प...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>एक साधारण उदाहरण के रूप में, मान लीजिए कि काम साझा करने की लागत 10...</td>\n",
       "      <td>आप अनुमान लगा सकते हैं कि काम साझा करने की लागत मूल डाक से कम है।</td>\n",
       "      <td>Yes</td>\n",
       "      <td>प्रस्तावना में कहा गया है कि काम साझा करने की लागत 10a है और मूल ड...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>आजादी के बाद यहां संसद बनाने की योजना शून्य हो गई।</td>\n",
       "      <td>इस स्थान के लिए संसद पर दृढ़ता से विचार किया गया था।</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>प्रस्तावना में कहा गया है कि आजादी के बाद संसद बनाने की योजना शून्...</td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>हाँ मैं उसे सुन सकता हूँ</td>\n",
       "      <td>मैं उसे सुन नहीं सकता.</td>\n",
       "      <td>No</td>\n",
       "      <td>The premise states \"हाँ मैं उसे सुन सकता हूँ,\" which translates to...</td>\n",
       "      <td>No</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>इस समूह में 23वां संशोधन भी है, जो कोलंबिया जिले में अन्यथा योग्य ...</td>\n",
       "      <td>23वें संशोधन में कहा गया है कि अगर आप कैलिफोर्निया में रहते हैं तो...</td>\n",
       "      <td>No</td>\n",
       "      <td>23वें संशोधन का संदर्भ कोलंबिया जिले में अन्यथा योग्य नागरिकों को ...</td>\n",
       "      <td>No</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>रिसॉर्ट के केंद्र में, भीतरी लैगून के आश्रय वाले पानी में, डॉल्फ़ि...</td>\n",
       "      <td>आप रिसॉर्ट में डोफिन के साथ तैर सकते हैं।</td>\n",
       "      <td>Yes</td>\n",
       "      <td>प्रस्तावना में कहा गया है कि रिसॉर्ट में डॉल्फ़िन कार्यक्रम के साथ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 premise  \\\n",
       "0  सुरक्षा सुनिश्चित करने के लिए जनरेटरों को बंद करना पड़ा और लिफ्ट ब...   \n",
       "1  भगवान का उल्लेख केवल प्रकृति के भगवान के रूप में किया जाता है, जिस...   \n",
       "2  अप्रैल १८६५ में उस व्यक्ति की हत्या के साथ, जिसने विचारों के एक नए...   \n",
       "3  दूसरे शब्दों में, क्या होता है कुछ की तरह है एक जादूगर के अब-तुम-अ...   \n",
       "4  आप जानते हैं, आप नहीं बच सकते, आप जीवित नहीं रह सकते अगर आपके पास ...   \n",
       "5  एक साधारण उदाहरण के रूप में, मान लीजिए कि काम साझा करने की लागत 10...   \n",
       "6                     आजादी के बाद यहां संसद बनाने की योजना शून्य हो गई।   \n",
       "7                                               हाँ मैं उसे सुन सकता हूँ   \n",
       "8  इस समूह में 23वां संशोधन भी है, जो कोलंबिया जिले में अन्यथा योग्य ...   \n",
       "9  रिसॉर्ट के केंद्र में, भीतरी लैगून के आश्रय वाले पानी में, डॉल्फ़ि...   \n",
       "\n",
       "                                                              hypothesis  \\\n",
       "0                                            जनरेटर एक सुरक्षा जोखिम थे।   \n",
       "1                                    लोग अलग-अलग होंगे लेकिन समान होंगे।   \n",
       "2                                       इस हमले को रूस ने अंजाम दिया था।   \n",
       "3                                    जो हो रहा है वह हैरान करने वाला है।   \n",
       "4                  आपको 5000 फीट से अधिक काउंटर प्रेशर की जरूरत होती है।   \n",
       "5      आप अनुमान लगा सकते हैं कि काम साझा करने की लागत मूल डाक से कम है।   \n",
       "6                   इस स्थान के लिए संसद पर दृढ़ता से विचार किया गया था।   \n",
       "7                                                 मैं उसे सुन नहीं सकता.   \n",
       "8  23वें संशोधन में कहा गया है कि अगर आप कैलिफोर्निया में रहते हैं तो...   \n",
       "9                              आप रिसॉर्ट में डोफिन के साथ तैर सकते हैं।   \n",
       "\n",
       "  example_answer  \\\n",
       "0            Yes   \n",
       "1            Yes   \n",
       "2        Neutral   \n",
       "3            Yes   \n",
       "4        Neutral   \n",
       "5            Yes   \n",
       "6        Neutral   \n",
       "7             No   \n",
       "8             No   \n",
       "9            Yes   \n",
       "\n",
       "                                                               reasoning  \\\n",
       "0  प्रस्तावना में कहा गया है कि सुरक्षा सुनिश्चित करने के लिए जनरेटरो...   \n",
       "1  प्रस्तावना में कहा गया है कि सभी लोगों को राष्ट्रों के समुदाय में ...   \n",
       "2  प्रस्तावना में यह कहा गया है कि एक व्यक्ति की हत्या अप्रैल 1865 मे...   \n",
       "3  प्रस्तावना में एक जादूगर के कार्यों का उल्लेख किया गया है, जो आमतौ...   \n",
       "4  प्रस्तावना में कहा गया है कि ऊंचाइयों पर सांस लेने के लिए काउंटर प...   \n",
       "5  प्रस्तावना में कहा गया है कि काम साझा करने की लागत 10a है और मूल ड...   \n",
       "6  प्रस्तावना में कहा गया है कि आजादी के बाद संसद बनाने की योजना शून्...   \n",
       "7  The premise states \"हाँ मैं उसे सुन सकता हूँ,\" which translates to...   \n",
       "8  23वें संशोधन का संदर्भ कोलंबिया जिले में अन्यथा योग्य नागरिकों को ...   \n",
       "9  प्रस्तावना में कहा गया है कि रिसॉर्ट में डॉल्फ़िन कार्यक्रम के साथ...   \n",
       "\n",
       "  pred_answer answer_exact_match  \n",
       "0         Yes          ✔️ [True]  \n",
       "1         Yes          ✔️ [True]  \n",
       "2          No                     \n",
       "3     Neutral                     \n",
       "4     Neutral          ✔️ [True]  \n",
       "5         Yes          ✔️ [True]  \n",
       "6          No                     \n",
       "7          No          ✔️ [True]  \n",
       "8          No          ✔️ [True]  \n",
       "9         Yes          ✔️ [True]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "70.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(cot_zeroshot, metric=indicxlni_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71278b5-0d1c-411a-98ed-86a6fb879798",
   "metadata": {},
   "source": [
    "---\n",
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8ec9c95-5c9d-4960-9708-bfc77bb96da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "copro_optimizer = COPRO(metric=indicxlni_accuracy, depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fae2a033-66a1-4a33-9645-63813e4b11df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:36:16 INFO dspy.teleprompt.copro_optimizer: Iteration Depth: 1/2.\n",
      "2025/06/21 14:36:17 INFO dspy.teleprompt.copro_optimizer: At Depth 1/2, Evaluating Prompt Candidate #1/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 35.00 / 50 (70.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 12.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:36:21 INFO dspy.evaluate.evaluate: Average Metric: 35 / 50 (70.0%)\n",
      "2025/06/21 14:36:21 INFO dspy.teleprompt.copro_optimizer: At Depth 1/2, Evaluating Prompt Candidate #2/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.00 / 50 (68.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 15.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:36:25 INFO dspy.evaluate.evaluate: Average Metric: 34 / 50 (68.0%)\n",
      "2025/06/21 14:36:25 INFO dspy.teleprompt.copro_optimizer: At Depth 1/2, Evaluating Prompt Candidate #3/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.00 / 50 (74.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 14.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:36:28 INFO dspy.evaluate.evaluate: Average Metric: 37 / 50 (74.0%)\n",
      "2025/06/21 14:36:28 INFO dspy.teleprompt.copro_optimizer: At Depth 1/2, Evaluating Prompt Candidate #4/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.00 / 50 (70.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 15.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:36:32 INFO dspy.evaluate.evaluate: Average Metric: 35 / 50 (70.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:36:32 INFO dspy.teleprompt.copro_optimizer: At Depth 1/2, Evaluating Prompt Candidate #5/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.00 / 50 (72.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 11.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:36:37 INFO dspy.evaluate.evaluate: Average Metric: 36 / 50 (72.0%)\n",
      "2025/06/21 14:36:37 INFO dspy.teleprompt.copro_optimizer: At Depth 1/2, Evaluating Prompt Candidate #6/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.00 / 50 (70.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:11<00:00,  4.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:36:49 INFO dspy.evaluate.evaluate: Average Metric: 35 / 50 (70.0%)\n",
      "2025/06/21 14:36:49 INFO dspy.teleprompt.copro_optimizer: At Depth 1/2, Evaluating Prompt Candidate #7/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.00 / 50 (66.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:36:53 INFO dspy.evaluate.evaluate: Average Metric: 33 / 50 (66.0%)\n",
      "2025/06/21 14:36:53 INFO dspy.teleprompt.copro_optimizer: At Depth 1/2, Evaluating Prompt Candidate #8/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.00 / 50 (68.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:36:59 INFO dspy.evaluate.evaluate: Average Metric: 34 / 50 (68.0%)\n",
      "2025/06/21 14:36:59 INFO dspy.teleprompt.copro_optimizer: At Depth 1/2, Evaluating Prompt Candidate #9/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.00 / 50 (68.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:08<00:00,  6.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:08 INFO dspy.evaluate.evaluate: Average Metric: 34 / 50 (68.0%)\n",
      "2025/06/21 14:37:08 INFO dspy.teleprompt.copro_optimizer: At Depth 1/2, Evaluating Prompt Candidate #10/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.00 / 50 (68.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:14 INFO dspy.evaluate.evaluate: Average Metric: 34 / 50 (68.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:17 INFO dspy.teleprompt.copro_optimizer: Iteration Depth: 2/2.\n",
      "2025/06/21 14:37:17 INFO dspy.teleprompt.copro_optimizer: At Depth 2/2, Evaluating Prompt Candidate #1/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 35.00 / 50 (70.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 13.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:21 INFO dspy.evaluate.evaluate: Average Metric: 35 / 50 (70.0%)\n",
      "2025/06/21 14:37:21 INFO dspy.teleprompt.copro_optimizer: At Depth 2/2, Evaluating Prompt Candidate #2/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.00 / 50 (68.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 16.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:25 INFO dspy.evaluate.evaluate: Average Metric: 34 / 50 (68.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:25 INFO dspy.teleprompt.copro_optimizer: At Depth 2/2, Evaluating Prompt Candidate #3/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 35.00 / 50 (70.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 15.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:28 INFO dspy.evaluate.evaluate: Average Metric: 35 / 50 (70.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:28 INFO dspy.teleprompt.copro_optimizer: At Depth 2/2, Evaluating Prompt Candidate #4/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 35.00 / 50 (70.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:34 INFO dspy.evaluate.evaluate: Average Metric: 35 / 50 (70.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:34 INFO dspy.teleprompt.copro_optimizer: At Depth 2/2, Evaluating Prompt Candidate #5/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.00 / 50 (72.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:39 INFO dspy.evaluate.evaluate: Average Metric: 36 / 50 (72.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:39 INFO dspy.teleprompt.copro_optimizer: At Depth 2/2, Evaluating Prompt Candidate #6/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 34.00 / 50 (68.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:45 INFO dspy.evaluate.evaluate: Average Metric: 34 / 50 (68.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:45 INFO dspy.teleprompt.copro_optimizer: At Depth 2/2, Evaluating Prompt Candidate #7/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 35.00 / 50 (70.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:51 INFO dspy.evaluate.evaluate: Average Metric: 35 / 50 (70.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:51 INFO dspy.teleprompt.copro_optimizer: At Depth 2/2, Evaluating Prompt Candidate #8/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 34.00 / 50 (68.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 10.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:56 INFO dspy.evaluate.evaluate: Average Metric: 34 / 50 (68.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:37:56 INFO dspy.teleprompt.copro_optimizer: At Depth 2/2, Evaluating Prompt Candidate #9/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 39.00 / 50 (78.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  9.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:38:02 INFO dspy.evaluate.evaluate: Average Metric: 39 / 50 (78.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:38:02 INFO dspy.teleprompt.copro_optimizer: At Depth 2/2, Evaluating Prompt Candidate #10/10 for Predictor 1 of 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 37.00 / 50 (74.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:04<00:00, 11.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:38:07 INFO dspy.evaluate.evaluate: Average Metric: 37 / 50 (74.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kwargs = dict(num_threads=64, display_progress=True)\n",
    "\n",
    "cot_copro = copro_optimizer.compile(cot_zeroshot, trainset=train_set, eval_kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5469ae2-1e06-4942-8fc8-9a976b853caa",
   "metadata": {},
   "source": [
    "#### Testing optimized prompt on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a006fffb-c76a-404e-abae-149ce248b7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.00 / 10 (70.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:20<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/21 14:40:34 INFO dspy.evaluate.evaluate: Average Metric: 7 / 10 (70.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>example_answer</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>सुरक्षा सुनिश्चित करने के लिए जनरेटरों को बंद करना पड़ा और लिफ्ट ब...</td>\n",
       "      <td>जनरेटर एक सुरक्षा जोखिम थे।</td>\n",
       "      <td>Yes</td>\n",
       "      <td>प्रस्तावना में कहा गया है कि सुरक्षा सुनिश्चित करने के लिए जनरेटरो...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>भगवान का उल्लेख केवल प्रकृति के भगवान के रूप में किया जाता है, जिस...</td>\n",
       "      <td>लोग अलग-अलग होंगे लेकिन समान होंगे।</td>\n",
       "      <td>Yes</td>\n",
       "      <td>प्रस्तावना में कहा गया है कि सभी लोगों को राष्ट्रों के समुदाय में ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>अप्रैल १८६५ में उस व्यक्ति की हत्या के साथ, जिसने विचारों के एक नए...</td>\n",
       "      <td>इस हमले को रूस ने अंजाम दिया था।</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>प्रस्तावना में यह कहा गया है कि एक व्यक्ति की हत्या हुई थी जिसने न...</td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>दूसरे शब्दों में, क्या होता है कुछ की तरह है एक जादूगर के अब-तुम-अ...</td>\n",
       "      <td>जो हो रहा है वह हैरान करने वाला है।</td>\n",
       "      <td>Yes</td>\n",
       "      <td>प्रस्तावना में एक जादूगर के कार्यों का उल्लेख किया गया है, जो दर्श...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>आप जानते हैं, आप नहीं बच सकते, आप जीवित नहीं रह सकते अगर आपके पास ...</td>\n",
       "      <td>आपको 5000 फीट से अधिक काउंटर प्रेशर की जरूरत होती है।</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>प्रस्तावना में कहा गया है कि ऊंचाइयों पर जीवित रहने के लिए काउंटर ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>एक साधारण उदाहरण के रूप में, मान लीजिए कि काम साझा करने की लागत 10...</td>\n",
       "      <td>आप अनुमान लगा सकते हैं कि काम साझा करने की लागत मूल डाक से कम है।</td>\n",
       "      <td>Yes</td>\n",
       "      <td>प्रस्तावना में कहा गया है कि काम साझा करने की लागत 10a है और मूल ड...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>आजादी के बाद यहां संसद बनाने की योजना शून्य हो गई।</td>\n",
       "      <td>इस स्थान के लिए संसद पर दृढ़ता से विचार किया गया था।</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>प्रस्तावना में कहा गया है कि आजादी के बाद संसद बनाने की योजना शून्...</td>\n",
       "      <td>No</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>हाँ मैं उसे सुन सकता हूँ</td>\n",
       "      <td>मैं उसे सुन नहीं सकता.</td>\n",
       "      <td>No</td>\n",
       "      <td>The premise states \"हाँ मैं उसे सुन सकता हूँ,\" which translates to...</td>\n",
       "      <td>No</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>इस समूह में 23वां संशोधन भी है, जो कोलंबिया जिले में अन्यथा योग्य ...</td>\n",
       "      <td>23वें संशोधन में कहा गया है कि अगर आप कैलिफोर्निया में रहते हैं तो...</td>\n",
       "      <td>No</td>\n",
       "      <td>23वां संशोधन कोलंबिया जिले में अन्यथा योग्य नागरिकों को राष्ट्रपति...</td>\n",
       "      <td>No</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>रिसॉर्ट के केंद्र में, भीतरी लैगून के आश्रय वाले पानी में, डॉल्फ़ि...</td>\n",
       "      <td>आप रिसॉर्ट में डोफिन के साथ तैर सकते हैं।</td>\n",
       "      <td>Yes</td>\n",
       "      <td>प्रस्तावना में कहा गया है कि रिसॉर्ट में डॉल्फ़िन कार्यक्रम के साथ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 premise  \\\n",
       "0  सुरक्षा सुनिश्चित करने के लिए जनरेटरों को बंद करना पड़ा और लिफ्ट ब...   \n",
       "1  भगवान का उल्लेख केवल प्रकृति के भगवान के रूप में किया जाता है, जिस...   \n",
       "2  अप्रैल १८६५ में उस व्यक्ति की हत्या के साथ, जिसने विचारों के एक नए...   \n",
       "3  दूसरे शब्दों में, क्या होता है कुछ की तरह है एक जादूगर के अब-तुम-अ...   \n",
       "4  आप जानते हैं, आप नहीं बच सकते, आप जीवित नहीं रह सकते अगर आपके पास ...   \n",
       "5  एक साधारण उदाहरण के रूप में, मान लीजिए कि काम साझा करने की लागत 10...   \n",
       "6                     आजादी के बाद यहां संसद बनाने की योजना शून्य हो गई।   \n",
       "7                                               हाँ मैं उसे सुन सकता हूँ   \n",
       "8  इस समूह में 23वां संशोधन भी है, जो कोलंबिया जिले में अन्यथा योग्य ...   \n",
       "9  रिसॉर्ट के केंद्र में, भीतरी लैगून के आश्रय वाले पानी में, डॉल्फ़ि...   \n",
       "\n",
       "                                                              hypothesis  \\\n",
       "0                                            जनरेटर एक सुरक्षा जोखिम थे।   \n",
       "1                                    लोग अलग-अलग होंगे लेकिन समान होंगे।   \n",
       "2                                       इस हमले को रूस ने अंजाम दिया था।   \n",
       "3                                    जो हो रहा है वह हैरान करने वाला है।   \n",
       "4                  आपको 5000 फीट से अधिक काउंटर प्रेशर की जरूरत होती है।   \n",
       "5      आप अनुमान लगा सकते हैं कि काम साझा करने की लागत मूल डाक से कम है।   \n",
       "6                   इस स्थान के लिए संसद पर दृढ़ता से विचार किया गया था।   \n",
       "7                                                 मैं उसे सुन नहीं सकता.   \n",
       "8  23वें संशोधन में कहा गया है कि अगर आप कैलिफोर्निया में रहते हैं तो...   \n",
       "9                              आप रिसॉर्ट में डोफिन के साथ तैर सकते हैं।   \n",
       "\n",
       "  example_answer  \\\n",
       "0            Yes   \n",
       "1            Yes   \n",
       "2        Neutral   \n",
       "3            Yes   \n",
       "4        Neutral   \n",
       "5            Yes   \n",
       "6        Neutral   \n",
       "7             No   \n",
       "8             No   \n",
       "9            Yes   \n",
       "\n",
       "                                                               reasoning  \\\n",
       "0  प्रस्तावना में कहा गया है कि सुरक्षा सुनिश्चित करने के लिए जनरेटरो...   \n",
       "1  प्रस्तावना में कहा गया है कि सभी लोगों को राष्ट्रों के समुदाय में ...   \n",
       "2  प्रस्तावना में यह कहा गया है कि एक व्यक्ति की हत्या हुई थी जिसने न...   \n",
       "3  प्रस्तावना में एक जादूगर के कार्यों का उल्लेख किया गया है, जो दर्श...   \n",
       "4  प्रस्तावना में कहा गया है कि ऊंचाइयों पर जीवित रहने के लिए काउंटर ...   \n",
       "5  प्रस्तावना में कहा गया है कि काम साझा करने की लागत 10a है और मूल ड...   \n",
       "6  प्रस्तावना में कहा गया है कि आजादी के बाद संसद बनाने की योजना शून्...   \n",
       "7  The premise states \"हाँ मैं उसे सुन सकता हूँ,\" which translates to...   \n",
       "8  23वां संशोधन कोलंबिया जिले में अन्यथा योग्य नागरिकों को राष्ट्रपति...   \n",
       "9  प्रस्तावना में कहा गया है कि रिसॉर्ट में डॉल्फ़िन कार्यक्रम के साथ...   \n",
       "\n",
       "  pred_answer answer_exact_match  \n",
       "0         Yes          ✔️ [True]  \n",
       "1         Yes          ✔️ [True]  \n",
       "2          No                     \n",
       "3     Neutral                     \n",
       "4     Neutral          ✔️ [True]  \n",
       "5         Yes          ✔️ [True]  \n",
       "6          No                     \n",
       "7          No          ✔️ [True]  \n",
       "8          No          ✔️ [True]  \n",
       "9         Yes          ✔️ [True]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "70.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator(cot_copro, metric=indicxlni_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2390dc94-ede4-443b-82f3-c9f35edf3b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': None,\n",
       " 'messages': [{'role': 'system',\n",
       "   'content': 'Your input fields are:\\n1. `premise` (str): \\n2. `hypothesis` (str):\\nYour output fields are:\\n1. `reasoning` (str): \\n2. `answer` (str): Yes or No or Neutral\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\n\\n[[ ## premise ## ]]\\n{premise}\\n\\n[[ ## hypothesis ## ]]\\n{hypothesis}\\n\\n[[ ## reasoning ## ]]\\n{reasoning}\\n\\n[[ ## answer ## ]]\\n{answer}\\n\\n[[ ## completed ## ]]\\nIn adhering to this structure, your objective is: \\n        Carefully examine the relationship between the given premise and hypothesis. Your task is to ascertain if the hypothesis can logically be inferred from the premise. Retreating into logic:, respond affirmatively with \"Yes\" if the hypothesis follows validly; denote doubt if \"Neutral\" applies where the hypothesis doesn\\'t contradict but isn\\'t confirmed either, or decisively declare \"No\" if it incoherently counters the premise.'},\n",
       "  {'role': 'user',\n",
       "   'content': '[[ ## premise ## ]]\\nरिसॉर्ट के केंद्र में, भीतरी लैगून के आश्रय वाले पानी में, डॉल्फ़िन कार्यक्रम के साथ एक तैराकी है।\\n\\n[[ ## hypothesis ## ]]\\nआप रिसॉर्ट में डोफिन के साथ तैर सकते हैं।\\n\\nRespond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.'}],\n",
       " 'kwargs': {},\n",
       " 'response': ModelResponse(id='chatcmpl-BkoX21ujaMO3nisaQJwaWbpdy93Jt', created=1750497032, model='gpt-4o-mini-2024-07-18', object='chat.completion', system_fingerprint='fp_34a54ae93c', choices=[Choices(finish_reason='stop', index=0, message=Message(content='[[ ## reasoning ## ]]\\nप्रस्तावना में कहा गया है कि रिसॉर्ट में डॉल्फ़िन कार्यक्रम के साथ तैराकी है, जिसका अर्थ है कि डॉल्फ़िन के साथ तैरने का अवसर उपलब्ध है। इसलिए, यह निष्कर्ष निकाला जा सकता है कि आप रिसॉर्ट में डॉल्फ़िन के साथ तैर सकते हैं। \\n\\n[[ ## answer ## ]]\\nYes\\n\\n[[ ## completed ## ]]', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]))], usage=Usage(completion_tokens=93, prompt_tokens=315, total_tokens=408, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default', cache_hit=None),\n",
       " 'outputs': ['[[ ## reasoning ## ]]\\nप्रस्तावना में कहा गया है कि रिसॉर्ट में डॉल्फ़िन कार्यक्रम के साथ तैराकी है, जिसका अर्थ है कि डॉल्फ़िन के साथ तैरने का अवसर उपलब्ध है। इसलिए, यह निष्कर्ष निकाला जा सकता है कि आप रिसॉर्ट में डॉल्फ़िन के साथ तैर सकते हैं। \\n\\n[[ ## answer ## ]]\\nYes\\n\\n[[ ## completed ## ]]'],\n",
       " 'usage': {'completion_tokens': 93,\n",
       "  'prompt_tokens': 315,\n",
       "  'total_tokens': 408,\n",
       "  'completion_tokens_details': CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None),\n",
       "  'prompt_tokens_details': PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)},\n",
       " 'cost': 0.00010304999999999998,\n",
       " 'timestamp': '2025-06-21T14:40:34.037953',\n",
       " 'uuid': 'c1770356-e915-449e-b02e-22f235b8183f',\n",
       " 'model': 'openai/gpt-4o-mini',\n",
       " 'response_model': 'gpt-4o-mini-2024-07-18',\n",
       " 'model_type': 'chat'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_copro.history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73345668-3e29-4066-8651-c74b62e68faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your input fields are:\n",
      "1. `premise` (str): \n",
      "2. `hypothesis` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `answer` (str): Yes or No or Neutral\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## premise ## ]]\n",
      "{premise}\n",
      "\n",
      "[[ ## hypothesis ## ]]\n",
      "{hypothesis}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Carefully examine the relationship between the given premise and hypothesis. Your task is to ascertain if the hypothesis can logically be inferred from the premise. Retreating into logic:, respond affirmatively with \"Yes\" if the hypothesis follows validly; denote doubt if \"Neutral\" applies where the hypothesis doesn't contradict but isn't confirmed either, or decisively declare \"No\" if it incoherently counters the premise.\n"
     ]
    }
   ],
   "source": [
    "print(cot_copro.history[-1]['messages'][0]['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce38fe0-8752-45d7-b86e-70cd7bdb35e0",
   "metadata": {},
   "source": [
    "### PROMPT CHANGES SHOWN\n",
    "\n",
    "#### Initial Prompt\n",
    "This is the prompt that we passed in `Signature`::\n",
    "\n",
    "----------------------------------------------------------------------------\n",
    "Your input fields are:\n",
    "1. `premise` (str): \n",
    "2. `hypothesis` (str):\n",
    "Your output fields are:\n",
    "1. `reasoning` (str): \n",
    "2. `answer` (str): Yes or No or Neutral\n",
    "All interactions will be structured in the following way, with the appropriate values filled in.\n",
    "\n",
    "[[ ## premise ## ]]\n",
    "{premise}\n",
    "\n",
    "[[ ## hypothesis ## ]]\n",
    "{hypothesis}\n",
    "\n",
    "[[ ## reasoning ## ]]\n",
    "{reasoning}\n",
    "\n",
    "[[ ## answer ## ]]\n",
    "{answer}\n",
    "\n",
    "[[ ## completed ## ]]\n",
    "In adhering to this structure, your objective is: \n",
    "        You are given a premise and a hypothesis.You must indicate with Yes/No/Neutral answer whether we can logically conclude the hypothesis from the premise.\n",
    "\n",
    "#### Prompt After Optimization\n",
    "Your input fields are:\n",
    "1. `premise` (str): \n",
    "2. `hypothesis` (str):\n",
    "Your output fields are:\n",
    "1. `reasoning` (str): \n",
    "2. `answer` (str): Yes or No or Neutral\n",
    "All interactions will be structured in the following way, with the appropriate values filled in.\n",
    "\n",
    "[[ ## premise ## ]]\n",
    "{premise}\n",
    "\n",
    "[[ ## hypothesis ## ]]\n",
    "{hypothesis}\n",
    "\n",
    "[[ ## reasoning ## ]]\n",
    "{reasoning}\n",
    "\n",
    "[[ ## answer ## ]]\n",
    "{answer}\n",
    "\n",
    "[[ ## completed ## ]]\n",
    "In adhering to this structure, your objective is: \n",
    "        Carefully examine the relationship between the given premise and hypothesis. Your task is to ascertain if the hypothesis can logically be inferred from the premise. Retreating into logic:, respond affirmatively with \"Yes\" if the hypothesis follows validly; denote doubt if \"Neutral\" applies where the hypothesis doesn't contradict but isn't confirmed either, or decisively declare \"No\" if it incoherently counters the premise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
